####################
 ## Ver 1.0         ## 
 ## Date 9/27/23    ##
 ## Author Mad Goat ##
####################

######################################################################################################################################
# Resaon for the is script is be see cleanly and easly the newst CVEs as they are posted to get ahead of exploits as fast as we can. #
######################################################################################################################################

from time import mktime
import feedparser
from datetime import datetime, timedelta
import re

# Function to remove HTML tags and specified text from a string
def remove_html_and_extra(text):
    # Remove HTML tags lol <b> and <h2> i was seeing 
    clean = re.compile('<.*?>')
    text = re.sub(clean, '', text)

    # Removes the  "Read more at https://www.tenable.com/cve/" i was getting due to it being nested in the description 
    text = re.sub(r'Read more at https://www\.tenable\.com/cve/\S+', '', text)

    return text

# Fixed path to save the text file (replace with your desired path)
# Will change to one for windows and shared drives this is just a test /Users/seanvoth/Desktop/CVE/output.txt
txt_path = "/Users/username/Desktop/CVE/output.txt"

# RSS feed URL
rss_feed_url = "https://www.tenable.com/cve/feeds?sort=newest"

# Parse the RSS feed
feed = feedparser.parse(rss_feed_url)

# Calculates the date 48 hours ago as 24 hours was not working 
fourty_eight_hours_ago = datetime.now() - timedelta(hours=48)

# Opens the text file for writing
with open(txt_path, 'w', encoding='utf-8') as txtfile:
    # Filter and write posts from the last 48 hours to the text file
    for entry in feed.entries:
        entry_date = datetime.fromtimestamp(
            mktime(entry.published_parsed)
        )

        # Checks if the post is from the last 48 hours
        if entry_date >= fourty_eight_hours_ago:
            title = remove_html_and_extra(entry.title)
            link = entry.link
            published_date = entry_date.strftime("%Y-%m-%d %H:%M:%S")
            
            # Checks if the entry has content since i was getting errors and blanks
            if 'content' in entry:
                # Use the first content element as the description
                description = remove_html_and_extra(entry.content[0].value)
            elif 'summary' in entry:
                # If there's no content, fall back to using the summary
                description = remove_html_and_extra(entry.summary)
            else:
                description = ""
            
            # Writes the data to the text file since the first attempt of making a cvs was just bugged 
            txtfile.write("Title: {}\n".format(title))
            txtfile.write("Link: {}\n".format(link))
            txtfile.write("Published Date: {}\n".format(published_date))
            txtfile.write("Description: {}\n\n".format(description))

print(f"Text file saved to {txt_path}")

#### Notes ####
# Next ver i want to continue to work on making this a .csv as to be able to sort the by serverity 
# Also want to make a menu so that i can have it spit out the CVEs or ZDI from https://www.zerodayinitiative.com/rss/published/ to do the same thing but with zero days 
